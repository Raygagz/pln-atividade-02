{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 02 [Extração e Pré-processamento de Dados + Expressões Regulares]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 02** deve ser feita utilizando o **Google Colab** com uma conta\n",
        "sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/83JggUJ1mhgWviEaA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 16/10 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        "\n",
        "`Artur Henrique Allen Santos [11201721987]`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA: `\n",
        "\n",
        "`Pedro Régio Shoji [11201721028]`\n"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: Capítulo 1`\n",
        "\n",
        "`Segundo capítulo: Capítulo 24`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` para identificar ERROS em 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        "Os capítulos devem ser selecionados na seguinte planilha:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**DICA:** Por favor, insira o seu nome ou da sua equipe na ordem definida na planilha. Por exemplo, se a linha correspondente ao o GRUPO 5 já foi preenchida, a próxima equipe (GRUPO 6) deverá ser informada na próxima linha da planilha.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TIPOS DE ERROS**\n",
        "---\n"
      ],
      "metadata": {
        "id": "eD_AJQhrwJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: consulta feita no ChatGPT\n",
        ">\n",
        "\n",
        "Um `programa Python` que utilize `expressões regulares` pode ajudar a identificar vários **tipos de erros** comuns em **livros**, especialmente erros de formatação e problemas relacionados à consistência do texto. Aqui estão alguns exemplos de erros comuns que podem ser identificados usando expressões regulares:\n",
        "\n",
        "* Erros de gramática e ortografia: erros de digitação, concordância verbal e nominal, uso incorreto de pontuação e outros erros gramaticais.\n",
        "\n",
        "* Problemas de formatação: você pode usar expressões regulares para encontrar erros de formatação, como espaços em excesso, tabulações inadequadas ou alinhamentos inconsistentes.\n",
        "\n",
        "* Abreviações e acrônimos: você pode usar expressões regulares para encontrar abreviações ou acrônimos que não foram definidos ou explicados anteriormente no texto.\n",
        "\n",
        "* Citações e referências: expressões regulares podem ser úteis para localizar citações ou referências que precisam de formatação especial.\n",
        "\n",
        "* OUTROS TIPOS DE ERROS: não considerem apenas os tipos de erros citados acima.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Lembre-se de que expressões regulares podem ser poderosas, mas também complexas. Dependendo da complexidade dos erros que você deseja identificar, pode ser necessário ajustar as expressões regulares de acordo com as características específicas do seu texto. Além disso, é importante ter em mente que as expressões regulares podem não ser a melhor ferramenta para todos os tipos de erros em livros, especialmente problemas mais contextuais ou semânticos, que podem exigir abordagens de PLN mais avançadas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gz0DTI0KYmn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A equipe que **realizar mais testes** e/ou **identificar mais erros** terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30). Os testes e possíveis erros devem ser contabizados de maneira separada.\n",
        "\n",
        ">\n",
        "\n",
        "Além disso, **por se tratar de um livro**, há um teste importante que deve ser feito. Lembre-se que o teste deve ser feito utilizando expressões regulares. A equipe que realizar esse teste, mesmo que o erro não ocorra nos capítulos selecionados, terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30).\n",
        "\n",
        "> A equipe pode considerar outros capítulos do livro para tentar identificar esse tipo de erro.\n",
        "\n",
        "**Se for a mesma equipe, o peso da avaliação será reduzido em 50% (caindo de 40 para 20)**.\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE**: a diminuição no peso da AVALIAÇÃO será aplicado para todos os membros da equipe. Esse critério será aplicado apenas para uma equipe, considerando como critério de desempate a equipe que entregar primeiro a atividade no formulário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# por favor, inserir o código a partir daqui...\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "urls = ['https://brasileiraspln.com/livro-pln/1a-edicao/parte1/cap1/cap1.html', 'https://brasileiraspln.com/livro-pln/1a-edicao/parte10/cap24/cap24.html']\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_url(url):\n",
        "  response = requests.get(url)\n",
        "\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "  content = soup.find('main', {'id': 'quarto-document-content'})\n",
        "\n",
        "  paragraphs = content.find_all('p')\n",
        "\n",
        "  text = ''\n",
        "\n",
        "  for p in paragraphs:\n",
        "    text += p.get_text()\n",
        "\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "JUelkl-aO451"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Find and print matches\n",
        "def find_and_print_matches(regex, text):\n",
        "    matches = re.findall(regex, text)\n",
        "    match_count = 0\n",
        "    if matches:\n",
        "        print(f\"Matches for {regex}:\")\n",
        "        for match in matches:\n",
        "            match_count += 1\n",
        "            print(\"   \", match)\n",
        "    else:\n",
        "        print(f\"No match found for {regex}\")\n",
        "\n",
        "    return match_count"
      ],
      "metadata": {
        "id": "Wy6meNJmiRCi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_tests(text, patterns):\n",
        "  matches_total = 0\n",
        "\n",
        "  for pattern in patterns:\n",
        "    matches_total += find_and_print_matches(pattern, text)\n",
        "\n",
        "  return matches_total"
      ],
      "metadata": {
        "id": "fyyaS-3RuuyO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Encontre pontuações seguidas\n",
        "punctuation_pattern = r'[.,!?;:]{2,}'\n",
        "\n",
        "# 2. Encontre espaços seguidos\n",
        "space_pattern = r'(\\w+)(\\s{2,})(\\w+)'\n",
        "\n",
        "# 3. Encontre espaço seguido de ponto\n",
        "space_punct_pattern = r'\\s+[.,;!?]'\n",
        "\n",
        "# 4. Encontre palavra seguindo uma pontuação\n",
        "punct_word_pattern = r'[.,;!?][a-zA-ZÀ-ÖØ-öø-ÿ]+'\n",
        "\n",
        "# 5. Certas palavras devem seguir uma vírgula\n",
        "etc_pattern = r'([a-zA-ZÀ-ÖØ-öø-ÿ]+\\s+)(pois|mas|etc.|porém)'\n",
        "\n",
        "# 6. Encontra letras maiusculas no meio de uma palavra\n",
        "upcase_pattern = r'[a-z]+[A-Z]\\w*'\n",
        "\n",
        "# 7. Encontra frases disjuntivas sem separação por vírgula\n",
        "ou_pattern = r'(ou\\s)(\\w+\\s)+(ou)'\n",
        "\n",
        "# 8. Encontra frases do tipo 'tem gerado' (preferível: gera)\n",
        "tem_pattern = r'(tem|terem)\\s(\\w+do)'\n",
        "\n",
        "# 9. Encontra número mal-formado\n",
        "bad_num_pattern = r'\\d+(\\.\\d+)?([,;:]\\d+)+'\n",
        "\n",
        "# 10. Encontra erro de concordância com é e são\n",
        "concordancia_pattern = r'(([a-z]+[a-rt-z])\\s(são)|([a-z]+s)\\s(é))'\n",
        "\n",
        "# 11. Palavras devem começar com letra maiúscula após ponto final ou ponto e vírgula\n",
        "capitalization_pattern = r'([.;] ?[a-z])'\n",
        "\n",
        "# 12. \"de Capítulo\" e \"em Capítulo\" ao invés de \"do Capítulo\" ou \"no Capítulo\"\n",
        "capitulo_pattern = r'((em|de) [Cc]apítulo)'\n",
        "\n",
        "# 13. Menções a componentes específicos do livro devem ser capitalizados, outros casos deverão usar caixa baixa.\n",
        "chapter_capitalization_pattern = r'((?<![.;]) ?(Capítulo|Quadro|Exemplo|Tabela|Apêndice|Figura) [^0-9]|(capítulo|quadro|exemplo|tabela|apêndice|Figura) [0-9])'\n",
        "\n",
        "\n",
        "#patterns = [verb_subject_agreement_pattern]\n",
        "patterns = [punctuation_pattern, space_pattern, space_punct_pattern, punct_word_pattern,\n",
        "            etc_pattern, upcase_pattern, ou_pattern, tem_pattern, bad_num_pattern,\n",
        "            concordancia_pattern, capitalization_pattern,capitulo_pattern,\n",
        "            chapter_capitalization_pattern]"
      ],
      "metadata": {
        "id": "HwJO0soMvs5q"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text_from_url(urls[0])"
      ],
      "metadata": {
        "id": "Qi30u4y6PgSt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = perform_tests(text, patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU3OekyJOACN",
        "outputId": "0b0f8831-2df7-4fc1-9993-994a8b30f4e3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches for [.,!?;:]{2,}:\n",
            "    .,\n",
            "Matches for (\\w+)(\\s{2,})(\\w+):\n",
            "    ('1', '  ', 'Exemplos')\n",
            "No match found for \\s+[.,;!?]\n",
            "Matches for [.,;!?][a-zA-ZÀ-ÖØ-öø-ÿ]+:\n",
            "    .Para\n",
            "    .O\n",
            "    .Situa\n",
            "    .Em\n",
            "    .É\n",
            "    .Esses\n",
            "    .Primeiramente\n",
            "    .Como\n",
            "    .É\n",
            "    .Quadro\n",
            "    .A\n",
            "    .Ao\n",
            "    .A\n",
            "    .Na\n",
            "    .Cada\n",
            "    .Até\n",
            "    .No\n",
            "    .O\n",
            "    .Nesse\n",
            "    .Além\n",
            "    .Antes\n",
            "    .openai\n",
            "    .com\n",
            "Matches for ([a-zA-ZÀ-ÖØ-öø-ÿ]+\\s+)(pois|mas|etc.|porém):\n",
            "    ('programação ', 'etc.')\n",
            "    ('inglês ', 'etc.')\n",
            "    ('ontológicos ', 'etc.')\n",
            "    ('lógicas ', 'etc.')\n",
            "Matches for [a-z]+[A-Z]\\w*:\n",
            "    hatGPT2\n",
            "    ferramentasNeste\n",
            "    oS\n",
            "No match found for (ou\\s)(\\w+\\s)+(ou)\n",
            "Matches for (tem|terem)\\s(\\w+do):\n",
            "    ('tem', 'acompanhado')\n",
            "No match found for \\d+(\\.\\d+)?([,;:]\\d+)+\n",
            "Matches for (([a-z]+[a-rt-z])\\s(são)|([a-z]+s)\\s(é)):\n",
            "    ('escrita são', 'escrita', 'são', '', '')\n",
            "    ('comportamento são', 'comportamento', 'são', '', '')\n",
            "    ('texto são', 'texto', 'são', '', '')\n",
            "Matches for ([.;] ?[a-z]):\n",
            "    ; j\n",
            "    . p\n",
            "    ; u\n",
            "    ; u\n",
            "    ; u\n",
            "    ; u\n",
            "    ; c\n",
            "    .o\n",
            "    .c\n",
            "No match found for ((em|de) [Cc]apítulo)\n",
            "No match found for ((?<![.;]) ?(Capítulo|Quadro|Exemplo|Tabela|Apêndice|Figura) [^0-9]|(capítulo|quadro|exemplo|tabela|apêndice|Figura) [0-9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text_from_url(urls[1])"
      ],
      "metadata": {
        "id": "ZN12aCl0OHfc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors += perform_tests(text, patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJuH9isRQtWA",
        "outputId": "65cbc63b-a2e7-4b9f-9530-86b92ca5628e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches for [.,!?;:]{2,}:\n",
            "    .,\n",
            "    .,\n",
            "No match found for (\\w+)(\\s{2,})(\\w+)\n",
            "Matches for \\s+[.,;!?]:\n",
            "     ,\n",
            "Matches for [.,;!?][a-zA-ZÀ-ÖØ-öø-ÿ]+:\n",
            "    .A\n",
            "    .Atualmente\n",
            "    .Um\n",
            "    .Esse\n",
            "    .Casos\n",
            "    .A\n",
            "    .Outra\n",
            "    .A\n",
            "    .A\n",
            "    .A\n",
            "    .Existem\n",
            "    .A\n",
            "    .Entre\n",
            "    .Os\n",
            "    .Dependendo\n",
            "    .São\n",
            "    .Há\n",
            "    .Os\n",
            "    .Um\n",
            "    .A\n",
            "    .O\n",
            "    .A\n",
            "    .Apesar\n",
            "    .Porém\n",
            "    .A\n",
            "    ?Essa\n",
            "    .O\n",
            "    .Muitas\n",
            "    .Nesse\n",
            "    .É\n",
            "    .Quando\n",
            "    .Se\n",
            "    .Além\n",
            "    ?Modelos\n",
            "    .Nesse\n",
            "    .Tão\n",
            "    .Temos\n",
            "    .Baseando\n",
            "Matches for ([a-zA-ZÀ-ÖØ-öø-ÿ]+\\s+)(pois|mas|etc.|porém):\n",
            "    ('política ', 'etc.')\n",
            "    ('quantidade ', 'mas')\n",
            "Matches for [a-z]+[A-Z]\\w*:\n",
            "    hatGPT\n",
            "    penAI\n",
            "    penAI\n",
            "    hatGPT\n",
            "    iaQuatro\n",
            "    iaQuatro\n",
            "    hatGPT\n",
            "    hatGPT\n",
            "    hatGPT\n",
            "Matches for (ou\\s)(\\w+\\s)+(ou):\n",
            "    ('ou ', 'que ', 'ou')\n",
            "    ('ou ', 'qualquer ', 'ou')\n",
            "    ('ou ', 'discriminatórios ', 'ou')\n",
            "    ('ou ', 'diretamente ', 'ou')\n",
            "    ('ou ', 'saída ', 'ou')\n",
            "    ('ou ', 'incorreta ', 'ou')\n",
            "Matches for (tem|terem)\\s(\\w+do):\n",
            "    ('tem', 'havido')\n",
            "    ('terem', 'sido')\n",
            "    ('terem', 'aprendido')\n",
            "    ('tem', 'sido')\n",
            "    ('tem', 'gerado')\n",
            "    ('tem', 'suscitado')\n",
            "Matches for \\d+(\\.\\d+)?([,;:]\\d+)+:\n",
            "    ('', ',6')\n",
            "    ('', ',5')\n",
            "Matches for (([a-z]+[a-rt-z])\\s(são)|([a-z]+s)\\s(é)):\n",
            "    ('es é', '', '', 'es', 'é')\n",
            "    ('ou são', 'ou', 'são', '', '')\n",
            "    ('tmicos é', '', '', 'tmicos', 'é')\n",
            "    ('que são', 'que', 'são', '', '')\n",
            "    ('que são', 'que', 'são', '', '')\n",
            "    ('mais é', '', '', 'mais', 'é')\n",
            "    ('problemas é', '', '', 'problemas', 'é')\n",
            "    ('que são', 'que', 'são', '', '')\n",
            "    ('rasil são', 'rasil', 'são', '', '')\n",
            "    ('explicabilidade são', 'explicabilidade', 'são', '', '')\n",
            "    ('responsabilidades é', '', '', 'responsabilidades', 'é')\n",
            "    ('es é', '', '', 'es', 'é')\n",
            "    ('geral são', 'geral', 'são', '', '')\n",
            "    ('pios é', '', '', 'pios', 'é')\n",
            "    ('omo são', 'omo', 'são', '', '')\n",
            "Matches for ([.;] ?[a-z]):\n",
            "    ; m\n",
            "    ; a\n",
            "    ; a\n",
            "Matches for ((em|de) [Cc]apítulo):\n",
            "    ('de Capítulo', 'de')\n",
            "    ('em Capítulo', 'em')\n",
            "No match found for ((?<![.;]) ?(Capítulo|Quadro|Exemplo|Tabela|Apêndice|Figura) [^0-9]|(capítulo|quadro|exemplo|tabela|apêndice|Figura) [0-9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlON7nJrQ3B2",
        "outputId": "4d67e923-7fc9-4c3f-a2f2-acd9ee305ed5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CirzAmPpQ4MF"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}